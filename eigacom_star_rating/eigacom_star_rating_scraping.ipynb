{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    q = q.replace('\\n', '').replace('（', '(').replace('）', ')')\n",
    "    print(\"START : \" + q)\n",
    "    q = re.sub(\"\\(.+\\)$\", \"\", \" \".join(q.split()[1:-3]), re.UNICODE)\n",
    "    query = re.sub('(!|\\u3000|/|\\s|>|<|\\.)+', \"%20\", q)\n",
    "    url_search = 'https://eiga.com/search/' + query\n",
    "    res_search = requests.get(url_search )\n",
    "    res_search.encoding = res_search.apparent_encoding\n",
    "    soup_search = BeautifulSoup(res_search.content, \"lxml\")\n",
    "    result =  soup_search.find('section', attrs={\"id\": \"rslt-movie\"})\n",
    "    if(result != None):\n",
    "        path = result.find('li', attrs={\"class\": \"col-s-3\"}).find('a')[\"href\"]\n",
    "        url_review = 'https://eiga.com' + path\n",
    "        return url_review\n",
    "    else:\n",
    "        print(\"**************************************************\")\n",
    "        print(q + \" HAS NO RESULT\")\n",
    "        print(\"**************************************************\")\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(query):\n",
    "    page_num = 1\n",
    "    data = {\n",
    "        \"id\": -1,\n",
    "        \"rating\": -1,\n",
    "        \"check-in\":-1,\n",
    "        \"review-count\":-1\n",
    "    }\n",
    "    url_review=search(query)\n",
    "    \n",
    "    if(url_review == \"error\"):\n",
    "        return \"error\"\n",
    "\n",
    "    res = requests.get(url_review)\n",
    "    res.encoding = res.apparent_encoding\n",
    "    soup = BeautifulSoup(res.content, \"lxml\")\n",
    "    \n",
    "    rating = soup.find('span', attrs={\"class\": \"rating-star\"})\n",
    "    review_count = soup.find('span', attrs={\"itemprop\": \"reviewCount\"})\n",
    "    check_in = soup.find('a', attrs={\"class\": \"icon-movie-checkin\"}).find('strong')\n",
    "    data[\"rating\"] = 0 if rating.text == '－' else float(rating.text)\n",
    "    data[\"review-count\"] = 0 if review_count is None else int(review_count.text)\n",
    "    data[\"check-in\"] = 0 if check_in is None else int(check_in.text)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../2018_movie_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for q in open(input_file, 'r', encoding='utf-8').readlines():\n",
    "    movie_id = int(q.split()[0])\n",
    "    output_file = './{0}.json'.format(movie_id)\n",
    "    with open(output_file, 'w') as f:\n",
    "        data = scrape(q)\n",
    "        if(data == \"error\"):\n",
    "            continue\n",
    "        data[\"id\"] = movie_id\n",
    "        jsn =  json.dumps(data,ensure_ascii=False, indent=2) \n",
    "        f.write(jsn)   \n",
    "    f.close()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
