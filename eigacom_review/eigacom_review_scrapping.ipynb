{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    q = q.replace('\\n', '')\n",
    "    print(\"START : \" + q)\n",
    "    q = re.sub(\"\\（.+語版\\）\", \"\", \" \".join(q.split()[:-3]))\n",
    "    query = re.sub('(!|\\u3000|/|\\s|>|<|\\.)+', \"%20\", q)\n",
    "    url_search = 'https://eiga.com/search/' + query\n",
    "    res_search = requests.get(url_search )\n",
    "    res_search.encoding = res_search.apparent_encoding\n",
    "    soup_search = BeautifulSoup(res_search.content, \"lxml\")\n",
    "    result =  soup_search.find('section', attrs={\"id\": \"rslt-movie\"})\n",
    "    if(result != None):\n",
    "        path = result.find('li', attrs={\"class\": \"col-s-3\"}).find('a')[\"href\"]\n",
    "        url_review = 'https://eiga.com' + path + 'review/all/'\n",
    "        return url_review\n",
    "    else:\n",
    "        print(\"**************************************************\")\n",
    "        print(q + \" HAS NO RESULT\")\n",
    "        print(\"**************************************************\")\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review(query):\n",
    "    page_num = 1\n",
    "    data = {\n",
    "        \"id\": -1,\n",
    "        \"reviews\":{\n",
    "            \"eigacom\":[],\n",
    "            \"filmarks\":[],\n",
    "            \"coco\":[],\n",
    "        }\n",
    "    }\n",
    "    url_review=search(query)\n",
    "    \n",
    "    if(url_review == \"error\"):\n",
    "        return \"error\"\n",
    "    \n",
    "    while(1):\n",
    "        res = requests.get(url_review + str(page_num))\n",
    "        res.encoding = res.apparent_encoding\n",
    "        soup = BeautifulSoup(res.content, \"lxml\")\n",
    "        if soup.find('div', attrs={\"class\": \"user-review\"}) == None: # ページ数の上限を超えたら\n",
    "            print('DONE : ' + query )\n",
    "            break\n",
    "            \n",
    "        for r in soup.find_all('div', attrs={\"class\": \"user-review\"}):\n",
    "            title = r.find('h2',attrs={\"class\": \"review-title\"}).find('a')\n",
    "            main_text =  r.find('div',attrs={\"class\": \"txt-block\"})\n",
    "            tgl_btn = main_text.find('div',attrs={\"class\": \"toggle-btn\"})\n",
    "            if tgl_btn != None:\n",
    "                tgl_btn.decompose()\n",
    "            d = title.text + \"\\n\" +  main_text.text.replace(\"\\n\", \"\")\n",
    "            data[\"reviews\"][\"eigacom\"].append(d)\n",
    "        page_num += 1\n",
    "        time.sleep(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../2018_movie_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "START : ZEN FOR NOTHING〜何でもない禅〜\t2018\t1\t2\n",
      "DONE : ZEN FOR NOTHING〜何でもない禅〜\t2018\t1\t2\n",
      "\n",
      "2\n",
      "START : 映画 中二病でも恋がしたい！ -Take On Me-\t2018\t1\t2\n",
      "DONE : 映画 中二病でも恋がしたい！ -Take On Me-\t2018\t1\t2\n",
      "\n",
      "3\n",
      "START : アンダー・ザ・ウォーター（ スウェーデン・ デンマーク・ フィンランド）\t2018\t1\t5\n",
      "**************************************************\n",
      "アンダー・ザ・ウォーター（ スウェーデン・ デンマーク・ フィンランド） HAS NO RESULT\n",
      "**************************************************\n",
      "4\n",
      "START : 嘘八百\t2018\t1\t5\n",
      "DONE : 嘘八百\t2018\t1\t5\n",
      "\n",
      "5\n",
      "START : キングスマン: ゴールデン・サークル\t2018\t1\t5\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for q in open(input_file, 'r', encoding='utf-8').readlines():\n",
    "    print(num)\n",
    "    output_file = './{0}.json'.format(num)\n",
    "    with open(output_file, 'w') as f:\n",
    "        data = scrape_review(q)\n",
    "        if(data == \"error\"):\n",
    "            num += 1\n",
    "            continue\n",
    "        data[\"id\"] = num\n",
    "        jsn =  json.dumps(data,ensure_ascii=False, indent=2) \n",
    "        f.write(jsn)   \n",
    "    f.close()\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
