{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_query(q):\n",
    "    q = q.replace('\\n', '')\n",
    "    q = q.replace('（', '(')\n",
    "    q = q.replace('）', ')')\n",
    "    q = re.sub(r\"\\(.+\\)$\", \"\", \" \".join(q))\n",
    "    q = re.sub('(!|\\u3000|/|\\\\s|>|<|\\\\.)+', \" \", q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(q):\n",
    "    url_search = 'https://eiga.com/search/{}'.format(requests.utils.quote(normalize_query(q), safe=''))\n",
    "    res_search = requests.get(url_search )\n",
    "    res_search.encoding = res_search.apparent_encoding\n",
    "    \n",
    "    soup_search = BeautifulSoup(res_search.content, \"lxml\")\n",
    "    result =  soup_search.find('section', attrs={\"id\": \"rslt-movie\"})\n",
    "    if result is not None:\n",
    "        path = result.find('li', attrs={\"class\": \"col-s-3\"}).find('a')[\"href\"]\n",
    "        url_review = 'https://eiga.com' + path + 'review/all/'\n",
    "        return url_review\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review(query):\n",
    "    page_num = 1\n",
    "    data = {\n",
    "        \"id\": -1,\n",
    "        \"reviews\":{\n",
    "            \"eigacom\":[],\n",
    "            \"filmarks\":[],\n",
    "            \"coco\":[],\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"START : \" + query)\n",
    "    url_review=search(query)\n",
    "    \n",
    "    if url_review is None:\n",
    "        logging.warning(\"**************************************************\")\n",
    "        logging.warning(q + \" HAS NO RESULT\")\n",
    "        logging.warning(\"**************************************************\")\n",
    "        return None\n",
    "    \n",
    "    while(1):\n",
    "        res = requests.get(url_review + str(page_num))\n",
    "        res.encoding = res.apparent_encoding\n",
    "        soup = BeautifulSoup(res.content, \"lxml\")\n",
    "        if soup.find('div', attrs={\"class\": \"user-review\"}) == None: # ページ数の上限を超えたら\n",
    "            print('DONE : ' + query )\n",
    "            break\n",
    "            \n",
    "        for r in soup.find_all('div', attrs={\"class\": \"user-review\"}):\n",
    "            title = r.find('h2',attrs={\"class\": \"review-title\"}).find('a')\n",
    "            main_text =  r.find('div',attrs={\"class\": \"txt-block\"})\n",
    "            tgl_btn = main_text.find('div',attrs={\"class\": \"toggle-btn\"})\n",
    "            if tgl_btn is not None:\n",
    "                tgl_btn.decompose()\n",
    "            d = title.text + \"\\n\" +  main_text.text.replace(\"\\n\", \"\")\n",
    "            data[\"reviews\"][\"eigacom\"].append(d)\n",
    "        page_num += 1\n",
    "        time.sleep(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open('../2018_movie_clean', 'r') as movie_clean:\n",
    "        for line in csv.reader(movie_clean, delimiter='\\t'):\n",
    "            movie_id, title, *_ = line\n",
    "            output_file = './{}.json'.format(movie_id)\n",
    "            with open(output_file, 'w') as f:\n",
    "                print(movie_id)\n",
    "                data = scrape_review(title)\n",
    "                if data == None:\n",
    "                    continue\n",
    "                data[\"id\"] = int(movie_id)\n",
    "                jsn =  json.dump(data, f, ensure_ascii=False, indent=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
