{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(y):\n",
    "    path = '../data/std_data/'\n",
    "    x_train_std = pd.read_pickle(path +'train/{}_x.pkl'.format(str(y))).values\n",
    "    x_test_std = pd.read_pickle(path +'test/{}_x.pkl'.format(str(y))).values\n",
    "    y_train = pd.read_pickle(path +'train/{}_y.pkl'.format(str(y))).values\n",
    "    y_test = pd.read_pickle(path +'test/{}_y.pkl'.format(str(y))).values\n",
    "    features = pd.read_pickle(path +'train/{}_x.pkl'.format(str(y))).columns\n",
    "    return x_train_std, x_test_std, y_train, y_test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    # ROC曲線をプロット\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
    "    plt.legend()\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # アンサンブルの重み  [w_lr, w_lda, w_sv, w_xgb, w_lgbm, w_cb, w_mlp]\n",
    "    w = np.array([0.10583359, 0.03752913, 0.26870715, 0.09771777, 0.10549716, 0., 0.3847152 ])\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm_all = np.zeros((2, 2))\n",
    "    \n",
    "    # 予測した確率全体を格納\n",
    "    probs_all_lr = np.array([])\n",
    "    probs_all_lda = np.array([])\n",
    "    probs_all_sv = np.array([])\n",
    "    probs_all_lgbm = np.array([])\n",
    "    probs_all_xgb = np.array([])\n",
    "    probs_all_cb = np.array([])\n",
    "    probs_all_mlp = np.array([])\n",
    "    \n",
    "    probs_all = np.array([])\n",
    "    y_true_all = np.array([])\n",
    "    \n",
    "    predict_rank = [0, 0, 0, 0, 0, 0] # 実際の受賞作品をモデルは何位と予想するかのカウント\n",
    "    \n",
    "    for y in range(1978, 2020):\n",
    "        \n",
    "        # データの生成\n",
    "        x_train_std, x_test_std, y_train, y_test, features = load_data(y)\n",
    "        y_true_all = np.hstack((y_true_all, y_test))\n",
    "       \n",
    "        # logistic regression\n",
    "        lr = LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\",  penalty=\"l2\", C=0.0001,  random_state=0,) # ロジスティック回帰モデルのインスタンスを作成\n",
    "        lr.fit(x_train_std, y_train) # ロジスティック回帰モデルの重みを学習\n",
    "        probs_lr = lr.predict_proba(x_test_std)[:,1]\n",
    "        probs_all_lr = np.hstack((probs_all_lr, probs_lr))\n",
    "        \n",
    "        # LDA\n",
    "        lda = LDA(solver=\"eigen\", shrinkage=1).fit(x_train_std,  y_train)\n",
    "        probs_lda = lda.predict_proba(x_test_std)[:,1]\n",
    "        probs_all_lda = np.hstack((probs_all_lda, probs_lda))\n",
    "        \n",
    "        # svm\n",
    "        sv = svm.SVR(kernel=\"sigmoid\",\n",
    "                                     degree=4,\n",
    "                                     gamma=0.043502212815589775,\n",
    "                                     coef0=0.20190829020616494,\n",
    "                                     tol=0.0001,\n",
    "                                     C=0.000245786293391316,\n",
    "                                     epsilon=0.3056167642389302,\n",
    "                                    verbose=False,)\n",
    "        sv.fit(x_train_std, y_train)\n",
    "        probs_sv = sv.predict(x_test_std)\n",
    "        probs_all_sv = np.hstack((probs_all_sv, probs_sv))\n",
    "        \n",
    "        # xgb\n",
    "        xgboost = xgb.XGBRegressor(silent= True, \n",
    "                                random_state=0,\n",
    "                               max_depth=4,\n",
    "                               learning_rate=0.12765177534095626,\n",
    "                               n_estimators = 46,\n",
    "                               gamma=0.060805284848630535,\n",
    "                               reg_lambda=4.995675788308118,\n",
    "                               reg_alpha=2.1912254426545754,\n",
    "                               sub_sample=0.45297631180790854,\n",
    "                               scale_pos_weight=1.1672978934986058)\n",
    "        xgboost.fit(x_train_std, y_train)\n",
    "        probs_xgb = xgboost.predict(x_test_std)\n",
    "        probs_all_xgb = np.hstack((probs_all_xgb, probs_xgb))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # lgbm\n",
    "        lgbm = lgb.LGBMRegressor(\n",
    "            random_state=0,\n",
    "            verbosity=-1,\n",
    "            bagging_seed=0,\n",
    "            boost_from_average='true',\n",
    "            metric='auc',\n",
    "            bagging_freq=4,\n",
    "            min_data_in_leaf=21,\n",
    "            max_depth=13,\n",
    "            learning_rate=0.08731913651405197,\n",
    "            n_estimators=3394,\n",
    "            subsample=0.7054763057027115,\n",
    "            num_leaves=438,\n",
    "            reg_lambda=0.9377125325944119,  \n",
    "        )\n",
    "        \n",
    "        lgbm.fit(x_train_std, y_train)\n",
    "        probs_lgbm = lgbm.predict(x_test_std)\n",
    "        probs_all_lgbm = np.hstack((probs_all_lgbm, probs_lgbm))\n",
    "        \n",
    "        # catboost\n",
    "        cb = catboost.CatBoostRegressor(\n",
    "             random_state=0,\n",
    "            iterations=258,\n",
    "            depth=2,\n",
    "            learning_rate=0.019083573879517587,\n",
    "            random_strength=84,\n",
    "            bagging_temperature=0.3233702745357832,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=32, \n",
    "            logging_level='Silent')\n",
    "        cb.fit(x_train_std, y_train)\n",
    "        probs_cb = cb.predict(x_test_std)\n",
    "        probs_all_cb = np.hstack((probs_all_cb, probs_cb))   \n",
    "        \n",
    "        # mlp\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(32,),\n",
    "                           activation='relu',\n",
    "                           solver='adam',\n",
    "                           alpha=4.76324733221396,\n",
    "                           batch_size='auto',\n",
    "                           learning_rate='constant', \n",
    "                           learning_rate_init=0.0012043271455668674, \n",
    "                           power_t=0.5,\n",
    "                           max_iter=1000, \n",
    "                           shuffle=True,\n",
    "                           random_state=0, \n",
    "                           tol=0.0001, \n",
    "                           verbose=False, \n",
    "                           warm_start=False, \n",
    "                           momentum=0.9,\n",
    "                           nesterovs_momentum=True, \n",
    "                           early_stopping=False, \n",
    "                           validation_fraction=0.1, \n",
    "                           beta_1=0.022158342014810775, \n",
    "                           beta_2= 0.7802116425099002,\n",
    "                           epsilon=1e-08,\n",
    "                           )\n",
    "        mlp.fit(x_train_std, y_train)\n",
    "        probs_mlp = mlp.predict(x_test_std)\n",
    "        probs_all_mlp = np.hstack((probs_all_mlp, probs_mlp))\n",
    "        \n",
    "        #アンサンブル\n",
    "        all_models_probs = [probs_lr, probs_lda, probs_sv, probs_xgb, probs_lgbm, probs_cb, probs_mlp]\n",
    "        # 各モデル結果の重み付き平均\n",
    "        probs_weighted_average = np.array([0 for i in range(len(y_test))], dtype='float64')\n",
    "        for probs, weight in zip(all_models_probs, w):\n",
    "            probs_weighted_average += (probs * weight)\n",
    "        probs_all = np.hstack((probs_all, probs_weighted_average))\n",
    "        \n",
    "        correct = \"o\" if np.max(probs_weighted_average) == probs_weighted_average[0] else \"x\"\n",
    "        \n",
    "        print(str(y) + \" : \" + correct)\n",
    "        if correct == \"x\":\n",
    "            print(\"予想順位: {0}, 確率: {1}\".format(np.where(np.argsort(-probs_weighted_average) == 0)[0][0] + 1, probs_weighted_average[0]))\n",
    "            print(\"予想1位の確率：　{0}\".format(np.max(probs_weighted_average)))\n",
    "        print(probs_weighted_average)\n",
    "        predict_rank[np.where(np.argsort(-probs_weighted_average) == 0)[0][0]]  =  predict_rank[np.where(np.argsort(-probs_weighted_average) == 0)[0][0]] + 1\n",
    "        print()\n",
    "        \n",
    "        # 混同行列\n",
    "        y_pred = np.where((probs_weighted_average ==  max(probs_weighted_average)), 1, 0) #確率→0/1\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_all += cm\n",
    "    \n",
    "    auc_lr = roc_auc_score(y_true_all, probs_all_lr)\n",
    "    auc_lda = roc_auc_score(y_true_all, probs_all_lda)\n",
    "    auc_sv = roc_auc_score(y_true_all, probs_all_sv)\n",
    "    auc_xgb = roc_auc_score(y_true_all, probs_all_xgb)\n",
    "    auc_lgbm = roc_auc_score(y_true_all, probs_all_lgbm)\n",
    "    auc_cb = roc_auc_score(y_true_all, probs_all_cb)\n",
    "    auc_mlp = roc_auc_score(y_true_all, probs_all_mlp)\n",
    "    auc = roc_auc_score(y_true_all, probs_all)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true_all, probs_all)\n",
    "    \n",
    "    plot_roc_curve(fpr, tpr, auc)\n",
    "    \n",
    "    for ind, rank in enumerate(predict_rank):\n",
    "        if ind == 0:\n",
    "            print(\"正解: {}\".format(rank))\n",
    "        else:\n",
    "            print(\"{0}位と予想: {1}\".format(ind + 1, rank))\n",
    "    print()\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(cm_all)\n",
    "    print(\"AUC LR: \",auc_lr)\n",
    "    print(\"AUC LDA: \",auc_lda)\n",
    "    print(\"AUC svm: \",auc_sv)\n",
    "    print(\"AUC xgb: \",auc_xgb)\n",
    "    print(\"AUC lgbm: \", auc_lgbm)\n",
    "    print(\"AUC CB: \",auc_cb)\n",
    "    print(\"AUC MLP: \",auc_mlp)\n",
    "    print(\"AUC: \",auc)\n",
    "    print()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978 : o\n",
      "[0.31749066 0.24344273 0.22403787 0.23340073 0.27214627]\n",
      "\n",
      "1979 : x\n",
      "予想順位: 2, 確率: 0.3192328025078011\n",
      "予想1位の確率：　0.33997984083435673\n",
      "[0.3192328  0.19673443 0.23039025 0.33997984 0.23195241]\n",
      "\n",
      "1980 : x\n",
      "予想順位: 2, 確率: 0.3150469604643332\n",
      "予想1位の確率：　0.3911693228245371\n",
      "[0.31504696 0.39116932 0.21851155 0.31273595 0.21835616]\n",
      "\n",
      "1981 : x\n",
      "予想順位: 2, 確率: 0.23942718377031683\n",
      "予想1位の確率：　0.27794894031042067\n",
      "[0.23942718 0.20306583 0.21572366 0.21307077 0.27794894]\n",
      "\n",
      "1982 : x\n",
      "予想順位: 3, 確率: 0.30596826677800515\n",
      "予想1位の確率：　0.39393517713037757\n",
      "[0.30596827 0.33565719 0.29762449 0.39393518 0.19291703]\n",
      "\n",
      "1983 : o\n",
      "[0.42711049 0.19757512 0.22894014 0.26260609 0.21943274]\n",
      "\n",
      "1984 : x\n",
      "予想順位: 5, 確率: 0.19822796863506745\n",
      "予想1位の確率：　0.29659804990261096\n",
      "[0.19822797 0.29659805 0.20710153 0.29183891 0.22759285]\n",
      "\n",
      "1985 : x\n",
      "予想順位: 2, 確率: 0.28389056760574943\n",
      "予想1位の確率：　0.2989227963604689\n",
      "[0.28389057 0.20536208 0.2989228  0.19616198 0.16294131]\n",
      "\n",
      "1986 : x\n",
      "予想順位: 5, 確率: 0.17928038724506246\n",
      "予想1位の確率：　0.29445638313748873\n",
      "[0.17928039 0.20709312 0.27019281 0.27983622 0.29445638]\n",
      "\n",
      "1987 : x\n",
      "予想順位: 4, 確率: 0.21340851314778791\n",
      "予想1位の確率：　0.24971496422768003\n",
      "[0.21340851 0.23031718 0.23296954 0.19821652 0.24971496]\n",
      "\n",
      "1988 : o\n",
      "[0.4076314  0.18936591 0.18916456 0.2392648  0.21108608]\n",
      "\n",
      "1989 : x\n",
      "予想順位: 3, 確率: 0.22550175011061854\n",
      "予想1位の確率：　0.3032466234862348\n",
      "[0.22550175 0.23185304 0.20432552 0.30324662 0.21373694]\n",
      "\n",
      "1990 : o\n",
      "[0.44818372 0.2190886  0.22972089 0.24182996 0.20889974]\n",
      "\n",
      "1991 : o\n",
      "[0.41065061 0.28125719 0.21519397 0.19362897 0.25459167]\n",
      "\n",
      "1992 : o\n",
      "[0.53250249 0.26388143 0.27883824 0.24767266 0.19594631]\n",
      "\n",
      "1993 : o\n",
      "[0.47049611 0.24963154 0.19538589 0.19198765 0.23751887]\n",
      "\n",
      "1994 : x\n",
      "予想順位: 2, 確率: 0.276944176134622\n",
      "予想1位の確率：　0.4405199618487673\n",
      "[0.27694418 0.44051996 0.21556812 0.23778714 0.19069246]\n",
      "\n",
      "1995 : o\n",
      "[0.30657984 0.19205099 0.19039776 0.19449518 0.24670319]\n",
      "\n",
      "1996 : x\n",
      "予想順位: 2, 確率: 0.3683696795764189\n",
      "予想1位の確率：　0.3940271527116779\n",
      "[0.36836968 0.20338874 0.21687226 0.39402715 0.19718668]\n",
      "\n",
      "1997 : o\n",
      "[0.42574274 0.20267183 0.2813051  0.25400354 0.23483034]\n",
      "\n",
      "1998 : x\n",
      "予想順位: 4, 確率: 0.2191559118100668\n",
      "予想1位の確率：　0.29588558816873556\n",
      "[0.21915591 0.2709199  0.20053143 0.23145132 0.29588559]\n",
      "\n",
      "1999 : o\n",
      "[0.35594107 0.21800982 0.20963976 0.2516352  0.29212162]\n",
      "\n",
      "2000 : o\n",
      "[0.37150273 0.21909517 0.17618188 0.25436321 0.20991116]\n",
      "\n",
      "2001 : x\n",
      "予想順位: 5, 確率: 0.20994729307093135\n",
      "予想1位の確率：　0.4191553429315103\n",
      "[0.20994729 0.41915534 0.30561244 0.26888523 0.22294072]\n",
      "\n",
      "2002 : o\n",
      "[0.41153355 0.26159688 0.2625173  0.18854116 0.20833468]\n",
      "\n",
      "2003 : o\n",
      "[0.53656052 0.21339328 0.20071662 0.17798404 0.18128861]\n",
      "\n",
      "2004 : x\n",
      "予想順位: 4, 確率: 0.22002827437276992\n",
      "予想1位の確率：　0.345300604661724\n",
      "[0.22002827 0.3453006  0.2312969  0.1791215  0.24080394]\n",
      "\n",
      "2005 : x\n",
      "予想順位: 2, 確率: 0.27414502219995174\n",
      "予想1位の確率：　0.45303132831342774\n",
      "[0.27414502 0.22813675 0.26007933 0.23322815 0.45303133]\n",
      "\n",
      "2006 : x\n",
      "予想順位: 2, 確率: 0.3694750925969538\n",
      "予想1位の確率：　0.4523241839755716\n",
      "[0.36947509 0.20779448 0.29294835 0.45232418 0.21702094]\n",
      "\n",
      "2007 : o\n",
      "[0.39521457 0.26796832 0.21322798 0.20602021 0.20161651]\n",
      "\n",
      "2008 : x\n",
      "予想順位: 2, 確率: 0.2642979925419799\n",
      "予想1位の確率：　0.538126631014033\n",
      "[0.26429799 0.23997851 0.2222838  0.53812663 0.235804  ]\n",
      "\n",
      "2009 : o\n",
      "[0.47733334 0.19055365 0.24090221 0.21865858 0.23531594]\n",
      "\n",
      "2010 : x\n",
      "予想順位: 2, 確率: 0.30813695482396763\n",
      "予想1位の確率：　0.349934795100561\n",
      "[0.30813695 0.21384396 0.24966042 0.17089592 0.3499348 ]\n",
      "\n",
      "2011 : x\n",
      "予想順位: 3, 確率: 0.2353391632644323\n",
      "予想1位の確率：　0.5452767030588329\n",
      "[0.23533916 0.5452767  0.19076969 0.22106453 0.2409812 ]\n",
      "\n",
      "2012 : o\n",
      "[0.2818273  0.18166634 0.19588144 0.21331235 0.19023139]\n",
      "\n",
      "2013 : x\n",
      "予想順位: 4, 確率: 0.19772391029674072\n",
      "予想1位の確率：　0.2600451698457126\n",
      "[0.19772391 0.24305877 0.18069327 0.26004517 0.22467597]\n",
      "\n",
      "2014 : o\n",
      "[0.45305542 0.20078313 0.25063322 0.35328122 0.23356751 0.21605508]\n",
      "\n",
      "2015 : o\n",
      "[0.27014421 0.20958326 0.19213099 0.21291535 0.16162074]\n",
      "\n",
      "2016 : o\n",
      "[0.29836852 0.28509153 0.17032653 0.24564634 0.20725164]\n",
      "\n",
      "2017 : o\n",
      "[0.29844253 0.24727435 0.20778218 0.20760397 0.20878017]\n",
      "\n",
      "2018 : o\n",
      "[0.30921896 0.21463698 0.20025798 0.17265623 0.2096009 ]\n",
      "\n",
      "2019 : o\n",
      "[0.4862679  0.23701665 0.22688969 0.30008063 0.19499423]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解: 22\n",
      "2位と予想: 10\n",
      "3位と予想: 3\n",
      "4位と予想: 4\n",
      "5位と予想: 3\n",
      "6位と予想: 0\n",
      "[22, 10, 3, 4, 3, 0]\n",
      "confusion_matrix: \n",
      "[[149.  20.]\n",
      " [ 20.  22.]]\n",
      "AUC LR:  0.7482389405466329\n",
      "AUC LDA:  0.7418991265145111\n",
      "AUC svm:  0.794590025359256\n",
      "AUC xgb:  0.7607072414764722\n",
      "AUC lgbm:  0.7602141448295294\n",
      "AUC CB:  0.7561284868977177\n",
      "AUC MLP:  0.777120315581854\n",
      "AUC:  0.7948717948717948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
