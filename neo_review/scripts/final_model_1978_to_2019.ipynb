{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(y):\n",
    "    path = '../data/std_data/'\n",
    "    x_train_std = pd.read_pickle(path +'train/{}_x.pkl'.format(str(y))).values\n",
    "    x_test_std = pd.read_pickle(path +'test/{}_x.pkl'.format(str(y))).values\n",
    "    y_train = pd.read_pickle(path +'train/{}_y.pkl'.format(str(y))).values\n",
    "    y_test = pd.read_pickle(path +'test/{}_y.pkl'.format(str(y))).values\n",
    "    features = pd.read_pickle(path +'train/{}_x.pkl'.format(str(y))).columns\n",
    "    return x_train_std, x_test_std, y_train, y_test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    # ROC曲線をプロット\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
    "    plt.legend()\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # アンサンブルの重み  [w_lr, w_lda, w_sv, w_xgb, w_lgbm, w_cb, w_mlp]\n",
    "    w = np.array([0.10583359, 0.03752913, 0.26870715, 0.09771777, 0.10549716, 0., 0.3847152 ])\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm_all = np.zeros((2, 2))\n",
    "    \n",
    "    # 予測した確率全体を格納\n",
    "    probs_all_lr = np.array([])\n",
    "    probs_all_lda = np.array([])\n",
    "    probs_all_sv = np.array([])\n",
    "    probs_all_lgbm = np.array([])\n",
    "    probs_all_xgb = np.array([])\n",
    "    probs_all_cb = np.array([])\n",
    "    probs_all_mlp = np.array([])\n",
    "    \n",
    "    probs_all = np.array([])\n",
    "    y_true_all = np.array([])\n",
    "    \n",
    "    predict_rank = [0, 0, 0, 0, 0, 0] # 実際の受賞作品をモデルは何位と予想するかのカウント\n",
    "    \n",
    "    for y in range(1978, 2020):\n",
    "        \n",
    "        # データの生成\n",
    "        x_train_std, x_test_std, y_train, y_test, features = load_data(y)\n",
    "        y_true_all = np.hstack((y_true_all, y_test))\n",
    "       \n",
    "        # logistic regression\n",
    "        lr = LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\",  penalty=\"l2\", C=0.0001,  random_state=0,) # ロジスティック回帰モデルのインスタンスを作成\n",
    "        lr.fit(x_train_std, y_train) # ロジスティック回帰モデルの重みを学習\n",
    "        probs_lr = lr.predict_proba(x_test_std)[:,1]\n",
    "        probs_all_lr = np.hstack((probs_all_lr, probs_lr))\n",
    "        \n",
    "        # LDA\n",
    "        lda = LDA(solver=\"eigen\", shrinkage=1).fit(x_train_std,  y_train)\n",
    "        probs_lda = lda.predict_proba(x_test_std)[:,1]\n",
    "        probs_all_lda = np.hstack((probs_all_lda, probs_lda))\n",
    "        \n",
    "        # svm\n",
    "        sv = svm.SVR(kernel=\"sigmoid\",\n",
    "                                     degree=4,\n",
    "                                     gamma=0.043502212815589775,\n",
    "                                     coef0=0.20190829020616494,\n",
    "                                     tol=0.0001,\n",
    "                                     C=0.000245786293391316,\n",
    "                                     epsilon=0.3056167642389302,\n",
    "                                    verbose=False,)\n",
    "        sv.fit(x_train_std, y_train)\n",
    "        probs_sv = sv.predict(x_test_std)\n",
    "        probs_all_sv = np.hstack((probs_all_sv, probs_sv))\n",
    "        \n",
    "        # xgb\n",
    "        xgboost = xgb.XGBRegressor(silent= True, \n",
    "                                random_state=0,\n",
    "                               max_depth=4,\n",
    "                               learning_rate=0.12765177534095626,\n",
    "                               n_estimators = 46,\n",
    "                               gamma=0.060805284848630535,\n",
    "                               reg_lambda=4.995675788308118,\n",
    "                               reg_alpha=2.1912254426545754,\n",
    "                               sub_sample=0.45297631180790854,\n",
    "                               scale_pos_weight=1.1672978934986058)\n",
    "        xgboost.fit(x_train_std, y_train)\n",
    "        probs_xgb = xgboost.predict(x_test_std)\n",
    "        probs_all_xgb = np.hstack((probs_all_xgb, probs_xgb))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # lgbm\n",
    "        lgbm = lgb.LGBMRegressor(\n",
    "            random_state=0,\n",
    "            verbosity=-1,\n",
    "            bagging_seed=0,\n",
    "            boost_from_average='true',\n",
    "            metric='auc',\n",
    "            bagging_freq=4,\n",
    "            min_data_in_leaf=21,\n",
    "            max_depth=13,\n",
    "            learning_rate=0.08731913651405197,\n",
    "            n_estimators=3394,\n",
    "            subsample=0.7054763057027115,\n",
    "            num_leaves=438,\n",
    "            reg_lambda=0.9377125325944119,  \n",
    "        )\n",
    "        \n",
    "        lgbm.fit(x_train_std, y_train)\n",
    "        probs_lgbm = lgbm.predict(x_test_std)\n",
    "        probs_all_lgbm = np.hstack((probs_all_lgbm, probs_lgbm))\n",
    "        \n",
    "        # catboost\n",
    "        cb = catboost.CatBoostRegressor(\n",
    "             random_state=0,\n",
    "            iterations=258,\n",
    "            depth=2,\n",
    "            learning_rate=0.019083573879517587,\n",
    "            random_strength=84,\n",
    "            bagging_temperature=0.3233702745357832,\n",
    "            od_type=\"Iter\",\n",
    "            od_wait=32, \n",
    "            logging_level='Silent')\n",
    "        cb.fit(x_train_std, y_train)\n",
    "        probs_cb = cb.predict(x_test_std)\n",
    "        probs_all_cb = np.hstack((probs_all_cb, probs_cb))   \n",
    "        \n",
    "        # mlp\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(32,),\n",
    "                           activation='relu',\n",
    "                           solver='adam',\n",
    "                           alpha=4.76324733221396,\n",
    "                           batch_size='auto',\n",
    "                           learning_rate='constant', \n",
    "                           learning_rate_init=0.0012043271455668674, \n",
    "                           power_t=0.5,\n",
    "                           max_iter=1000, \n",
    "                           shuffle=True,\n",
    "                           random_state=0, \n",
    "                           tol=0.0001, \n",
    "                           verbose=False, \n",
    "                           warm_start=False, \n",
    "                           momentum=0.9,\n",
    "                           nesterovs_momentum=True, \n",
    "                           early_stopping=False, \n",
    "                           validation_fraction=0.1, \n",
    "                           beta_1=0.022158342014810775, \n",
    "                           beta_2= 0.7802116425099002,\n",
    "                           epsilon=1e-08,\n",
    "                           )\n",
    "        mlp.fit(x_train_std, y_train)\n",
    "        probs_mlp = mlp.predict(x_test_std)\n",
    "        probs_all_mlp = np.hstack((probs_all_mlp, probs_mlp))\n",
    "        \n",
    "        #アンサンブル\n",
    "        all_models_probs = [probs_lr, probs_lda, probs_sv, probs_xgb, probs_lgbm, probs_cb, probs_mlp]\n",
    "        # 各モデル結果の重み付き平均\n",
    "        probs_weighted_average = np.array([0 for i in range(len(y_test))], dtype='float64')\n",
    "        for probs, weight in zip(all_models_probs, w):\n",
    "            probs_weighted_average += (probs * weight)\n",
    "        probs_all = np.hstack((probs_all, probs_weighted_average))\n",
    "        \n",
    "        probs_weighted_average = softmax(probs_weighted_average)  # ソフトマックス関数で確率に\n",
    "        \n",
    "        correct = \"o\" if np.max(probs_weighted_average) == probs_weighted_average[0] else \"x\"\n",
    "        \n",
    "        print(str(y) + \" : \" + correct)\n",
    "        if correct == \"x\":\n",
    "            print(\"予想順位: {0}, 確率: {1}\".format(np.where(np.argsort(-probs_weighted_average) == 0)[0][0] + 1, probs_weighted_average[0]))\n",
    "            print(\"予想1位の確率：　{0}\".format(np.max(probs_weighted_average)))\n",
    "        print(probs_weighted_average)\n",
    "        predict_rank[np.where(np.argsort(-probs_weighted_average) == 0)[0][0]]  =  predict_rank[np.where(np.argsort(-probs_weighted_average) == 0)[0][0]] + 1\n",
    "        print()\n",
    "        \n",
    "        # 混同行列\n",
    "        y_pred = np.where((probs_weighted_average ==  max(probs_weighted_average)), 1, 0) #確率→0/1\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_all += cm\n",
    "    \n",
    "    auc_lr = roc_auc_score(y_true_all, probs_all_lr)\n",
    "    auc_lda = roc_auc_score(y_true_all, probs_all_lda)\n",
    "    auc_sv = roc_auc_score(y_true_all, probs_all_sv)\n",
    "    auc_xgb = roc_auc_score(y_true_all, probs_all_xgb)\n",
    "    auc_lgbm = roc_auc_score(y_true_all, probs_all_lgbm)\n",
    "    auc_cb = roc_auc_score(y_true_all, probs_all_cb)\n",
    "    auc_mlp = roc_auc_score(y_true_all, probs_all_mlp)\n",
    "    auc = roc_auc_score(y_true_all, probs_all)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true_all, probs_all)\n",
    "    \n",
    "    plot_roc_curve(fpr, tpr, auc)\n",
    "    \n",
    "    for ind, rank in enumerate(predict_rank):\n",
    "        if ind == 0:\n",
    "            print(\"正解: {}\".format(rank))\n",
    "        else:\n",
    "            print(\"{0}位と予想: {1}\".format(ind + 1, rank))\n",
    "    print()\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(cm_all)\n",
    "    print(\"AUC LR: \",auc_lr)\n",
    "    print(\"AUC LDA: \",auc_lda)\n",
    "    print(\"AUC svm: \",auc_sv)\n",
    "    print(\"AUC xgb: \",auc_xgb)\n",
    "    print(\"AUC lgbm: \", auc_lgbm)\n",
    "    print(\"AUC CB: \",auc_cb)\n",
    "    print(\"AUC MLP: \",auc_mlp)\n",
    "    print(\"AUC: \",auc)\n",
    "    print()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1978 : o\n",
      "[0.21211494 0.1969757  0.19319026 0.19500757 0.20271153]\n",
      "\n",
      "1979 : x\n",
      "予想順位: 2, 確率: 0.21110047235878657\n",
      "予想1位の確率：　0.2155259307874774\n",
      "[0.21110047 0.18676214 0.19315474 0.21552593 0.19345672]\n",
      "\n",
      "1980 : x\n",
      "予想順位: 2, 確率: 0.20439027550102468\n",
      "予想1位の確率：　0.22055644394326254\n",
      "[0.20439028 0.22055644 0.18558182 0.20391847 0.18555299]\n",
      "\n",
      "1981 : x\n",
      "予想順位: 2, 確率: 0.20185186194560692\n",
      "予想1位の確率：　0.20977925856859042\n",
      "[0.20185186 0.19464409 0.19712352 0.19660127 0.20977926]\n",
      "\n",
      "1982 : x\n",
      "予想順位: 3, 確率: 0.19972510377099267\n",
      "予想1位の確率：　0.21809022434070122\n",
      "[0.1997251  0.20574363 0.19806558 0.21809022 0.17837547]\n",
      "\n",
      "1983 : o\n",
      "[0.23386803 0.18590236 0.1918256  0.19839353 0.19001048]\n",
      "\n",
      "1984 : x\n",
      "予想順位: 5, 確率: 0.19083179888302298\n",
      "予想1位の確率：　0.21055828164177962\n",
      "[0.1908318  0.21055828 0.19253269 0.20955859 0.19651864]\n",
      "\n",
      "1985 : x\n",
      "予想順位: 2, 確率: 0.21089438717870618\n",
      "予想1位の確率：　0.2140885473753271\n",
      "[0.21089439 0.19496674 0.21408855 0.19318125 0.18686907]\n",
      "\n",
      "1986 : x\n",
      "予想順位: 5, 確率: 0.1868728377473743\n",
      "予想1位の確率：　0.20968457324881426\n",
      "[0.18687284 0.19214323 0.2046581  0.20664125 0.20968457]\n",
      "\n",
      "1987 : x\n",
      "予想順位: 4, 確率: 0.19767915096301217\n",
      "予想1位の確率：　0.20498805676206505\n",
      "[0.19767915 0.20105006 0.20158403 0.19469871 0.20498806]\n",
      "\n",
      "1988 : o\n",
      "[0.23395807 0.18808169 0.18804383 0.19770486 0.19221155]\n",
      "\n",
      "1989 : x\n",
      "予想順位: 3, 確率: 0.1978408085401701\n",
      "予想1位の確率：　0.2138356188029607\n",
      "[0.19784081 0.19910135 0.19369533 0.21383562 0.19552689]\n",
      "\n",
      "1990 : o\n",
      "[0.23810982 0.18935752 0.19138157 0.19371311 0.18743798]\n",
      "\n",
      "1991 : o\n",
      "[0.22927847 0.20145053 0.18857214 0.18454912 0.19614974]\n",
      "\n",
      "1992 : o\n",
      "[0.24957864 0.19078612 0.19366112 0.18771864 0.17825549]\n",
      "\n",
      "1993 : o\n",
      "[0.24328549 0.19507246 0.18477251 0.18414568 0.19272386]\n",
      "\n",
      "1994 : x\n",
      "予想順位: 2, 確率: 0.20011418122402916\n",
      "予想1位の確率：　0.23567739404481663\n",
      "[0.20011418 0.23567739 0.18820129 0.19242974 0.1835774 ]\n",
      "\n",
      "1995 : o\n",
      "[0.21654637 0.19311307 0.19279407 0.19358565 0.20396085]\n",
      "\n",
      "1996 : x\n",
      "予想順位: 2, 確率: 0.21853209966503004\n",
      "予想1位の確率：　0.22421163078089212\n",
      "[0.2185321  0.18529552 0.18781088 0.22421163 0.18414987]\n",
      "\n",
      "1997 : o\n",
      "[0.23073529 0.18460164 0.19970344 0.19432498 0.19063464]\n",
      "\n",
      "1998 : x\n",
      "予想順位: 4, 確率: 0.1950535775832708\n",
      "予想1位の確率：　0.21060913061794376\n",
      "[0.19505358 0.20541622 0.19145443 0.19746665 0.21060913]\n",
      "\n",
      "1999 : o\n",
      "[0.21861842 0.19045131 0.18886388 0.1969642  0.2051022 ]\n",
      "\n",
      "2000 : o\n",
      "[0.2261697  0.19419796 0.18604057 0.20116915 0.19242261]\n",
      "\n",
      "2001 : x\n",
      "予想順位: 5, 確率: 0.18494955996277512\n",
      "予想1位の確率：　0.2279875880085425\n",
      "[0.18494956 0.22798759 0.20351674 0.19617774 0.18736837]\n",
      "\n",
      "2002 : o\n",
      "[0.23049152 0.19839845 0.19858115 0.18442109 0.1881078 ]\n",
      "\n",
      "2003 : o\n",
      "[0.26053605 0.18858974 0.18621415 0.18202877 0.18263129]\n",
      "\n",
      "2004 : x\n",
      "予想順位: 4, 確率: 0.1950952645447867\n",
      "予想1位の確率：　0.22113210999174643\n",
      "[0.19509526 0.22113211 0.19730615 0.18727558 0.1991909 ]\n",
      "\n",
      "2005 : x\n",
      "予想順位: 2, 確率: 0.19619920854659612\n",
      "予想1位の確率：　0.23463164571083028\n",
      "[0.19619921 0.18737693 0.19345885 0.18833337 0.23463165]\n",
      "\n",
      "2006 : x\n",
      "予想順位: 2, 確率: 0.21177390421523964\n",
      "予想1位の確率：　0.23006647925430612\n",
      "[0.2117739  0.18015878 0.19617213 0.23006648 0.1818287 ]\n",
      "\n",
      "2007 : o\n",
      "[0.22905603 0.20168769 0.19094398 0.18957264 0.18873966]\n",
      "\n",
      "2008 : x\n",
      "予想順位: 2, 確率: 0.19150750016972054\n",
      "予想1位の確率：　0.2518303412332128\n",
      "[0.1915075  0.18690631 0.18362815 0.25183034 0.1861277 ]\n",
      "\n",
      "2009 : o\n",
      "[0.2440671  0.18321558 0.19267639 0.18843788 0.19160305]\n",
      "\n",
      "2010 : x\n",
      "予想順位: 2, 確率: 0.20974649114054383\n",
      "予想1位の確率：　0.21869924090050738\n",
      "[0.20974649 0.19087268 0.19783297 0.18284862 0.21869924]\n",
      "\n",
      "2011 : x\n",
      "予想順位: 3, 確率: 0.18828016748706874\n",
      "予想1位の確率：　0.2566898754417672\n",
      "[0.18828017 0.25668988 0.18007287 0.18561163 0.18934545]\n",
      "\n",
      "2012 : o\n",
      "[0.21419748 0.1937827  0.19655701 0.20001322 0.19544959]\n",
      "\n",
      "2013 : x\n",
      "予想順位: 4, 確率: 0.19526999437142858\n",
      "予想1位の確率：　0.20782667664735105\n",
      "[0.19526999 0.20432626 0.19197258 0.20782668 0.20060449]\n",
      "\n",
      "2014 : o\n",
      "[0.19643487 0.1526364  0.16043819 0.17778176 0.15772343 0.15498535]\n",
      "\n",
      "2015 : o\n",
      "[0.21241686 0.19993448 0.19647544 0.20060179 0.19057145]\n",
      "\n",
      "2016 : o\n",
      "[0.21149779 0.2087083  0.18607923 0.20063601 0.19307866]\n",
      "\n",
      "2017 : o\n",
      "[0.2131809  0.2025472  0.19470406 0.19466937 0.19489847]\n",
      "\n",
      "2018 : o\n",
      "[0.21814755 0.19846042 0.19562718 0.19030137 0.19746347]\n",
      "\n",
      "2019 : o\n",
      "[0.24222784 0.18878854 0.18688633 0.20107772 0.18101956]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解: 22\n",
      "2位と予想: 10\n",
      "3位と予想: 3\n",
      "4位と予想: 4\n",
      "5位と予想: 3\n",
      "6位と予想: 0\n",
      "\n",
      "confusion_matrix: \n",
      "[[149.  20.]\n",
      " [ 20.  22.]]\n",
      "AUC LR:  0.7482389405466329\n",
      "AUC LDA:  0.7418991265145111\n",
      "AUC svm:  0.794590025359256\n",
      "AUC xgb:  0.7607072414764722\n",
      "AUC lgbm:  0.7602141448295294\n",
      "AUC CB:  0.7561284868977177\n",
      "AUC MLP:  0.777120315581854\n",
      "AUC:  0.7948717948717948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
