{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_pickle('../data/dataframes/data.pkl')\n",
    "    nomination_onehot = pd.read_pickle('../data/dataframes/nomination_onehot.pkl')\n",
    "    selected_performers_onehot = pd.read_pickle('../data/dataframes/selected_performers_onehot.pkl')\n",
    "    selected_directors_onehot = pd.read_pickle('../data/dataframes/selected_directors_onehot.pkl')\n",
    "    selected_studio_onehot = pd.read_pickle('../data/dataframes/selected_studio_onehot.pkl')\n",
    "    selected_scriptwriter_onehot = pd.read_pickle('../data/dataframes/selected_scriptwriter_onehot.pkl')\n",
    "    review_dataframe = pd.read_pickle('../data/dataframes/review_dataframe.pkl')\n",
    "\n",
    "    \n",
    "    # selected_directors_onehotとselected_scriptwriter_onehotの重複した人\n",
    "    duplicate_scriptwriter = set(selected_directors_onehot.columns) & set(selected_scriptwriter_onehot.columns)\n",
    "    selected_scriptwriter_onehot = selected_scriptwriter_onehot.drop(duplicate_scriptwriter, axis=1)\n",
    "    \n",
    "    frames = [nomination_onehot,selected_performers_onehot,selected_directors_onehot,selected_studio_onehot,selected_scriptwriter_onehot,]\n",
    "\n",
    "    df = data\n",
    "    for f in frames:\n",
    "        df = pd.merge(df, f, on='id')\n",
    "    \n",
    "    drop_elements = [\"director\", \"other_nominates\", \"performers\", \"production_studio\", \"scriptwriter\", \"title\",  'selected_performers', 'selected_directors', 'selected_studio',\n",
    "       'selected_scriptwriter']\n",
    "    df_drop = df.drop(drop_elements, axis=1)\n",
    "\n",
    "    return df_drop, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(x_train, x_test):\n",
    "    stdsc = StandardScaler()\n",
    "\n",
    "    # 訓練用のデータを標準化\n",
    "    x_train_std = stdsc.fit_transform(x_train)\n",
    "    # 訓練用データを基準にテストデータも標準化\n",
    "    x_test_std = stdsc.transform(x_test)\n",
    "    \n",
    "    return x_train_std, x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多重共線性の排除 (共分散0.7以上のfeatureを削除)\n",
    "\n",
    "def collinearity(X):\n",
    "\n",
    "    # 改善前\n",
    "#     cor=np.corrcoef(X.T)\n",
    "#     type(cor)\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "#     sns.heatmap(cor, vmin=0.70,vmax=1,cmap=plt.cm.Spectral_r)\n",
    "\n",
    "    # 改善\n",
    "    drop_clm = ['吉田一夫']\n",
    "    X = X.drop(drop_clm,  axis=1)\n",
    "\n",
    "    # 改善後\n",
    "    \n",
    "#     cor=np.corrcoef(X.T)\n",
    "#     type(cor)\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "#     sns.heatmap(cor, vmin=0.80,vmax=1,cmap=plt.cm.Spectral_r)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(test_year):\n",
    "    df, data = load_data()\n",
    "    \n",
    "    df = collinearity(df)\n",
    "    \n",
    "    train = df.loc[df[\"year\"] != test_year]\n",
    "    test = df.loc[df[\"year\"] == test_year]\n",
    "    \n",
    "    # 入力データの作成\n",
    "    y_train = train['prize'].ravel()\n",
    "    x_train = train.drop(['prize', 'year'], axis=1)\n",
    "    \n",
    "    features = x_train.columns\n",
    "    \n",
    "    x_train = x_train.values # 学習データ\n",
    "    \n",
    "    # テストデータの作成\n",
    "    y_test = test['prize'].ravel()\n",
    "    x_test = test.drop(['prize', 'year'], axis=1)\n",
    "    x_test = x_test.values # テストデータ\n",
    "\n",
    "    # データの標準化\n",
    "    x_train_std, x_test_std = standard(x_train, x_test)\n",
    "    \n",
    "    return x_train_std, x_test_std, y_train, y_test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc):\n",
    "    # ROC曲線をプロット\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc)\n",
    "    plt.legend()\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    lr = LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\",  penalty=\"l2\", C=0.0001)\n",
    "    \n",
    "    sv = svm.SVR(kernel=\"poly\",\n",
    "                                 degree=8,\n",
    "                                 gamma=0.03521735642853326,\n",
    "                                 coef0=0.34010389238140537,\n",
    "                                 tol=1e-05,\n",
    "                                 C=0.001,\n",
    "                                 epsilon=0.14620884632948022)\n",
    "\n",
    "    xgboost = xgb.XGBRegressor(silent= True, \n",
    "                           max_depth=1,\n",
    "                           learning_rate=0.14544434403253392,\n",
    "                           n_estimators = 72,\n",
    "                           gamma=0.4356018082020117,\n",
    "                           reg_lambda=2.931451663505623,\n",
    "                           reg_alpha=0.19045302677956732)\n",
    "\n",
    "    # lgbm = lgb.LGBMRegressor(\n",
    "    #     verbosity=1,\n",
    "    #     boost_from_average='true',\n",
    "    #     metric='auc',\n",
    "    #     bagging_freq=5,\n",
    "    #     max_depth=19,\n",
    "    #     learning_rate=0.09802221664336347,\n",
    "    #     n_estimators=703,\n",
    "    #     subsample=0.7596658467659505,\n",
    "    #     reg_lambda=0.4087114877863393,\n",
    "    # )\n",
    "\n",
    "    # estimators = [('lr', lr), ('svm', sv), ('xgboost',xgboost), ('lgbm', lgbm)]\n",
    "    estimators = [('svm', sv)]\n",
    "    \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    cm_all = np.zeros((2, 2))\n",
    "    \n",
    "    # 予測した確率全体を格納\n",
    "    probs_all = np.array([])\n",
    "    y_true_all = np.array([])\n",
    "    \n",
    "    for y in range(1978, 2020):\n",
    "        \n",
    "        # データの生成\n",
    "        x_train_std, x_test_std, y_train, y_test, features = data_processing(y)\n",
    "        lr = LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\",  penalty=\"l2\", C=0.0001)\n",
    "        # 学習\n",
    "        estimators = create_models()\n",
    "        lr = VotingRegressor(estimators)\n",
    "        lr.fit(x_train_std, y_train)\n",
    "        \n",
    "        # 予測(確率)\n",
    "        probs = lr.predict(x_test_std)\n",
    "        probs_all = np.hstack((probs_all, probs))\n",
    "        y_true_all = np.hstack((y_true_all, y_test))\n",
    "\n",
    "        # 混同行列\n",
    "        y_pred = np.where((probs ==  max(probs)), 1, 0) #確率→0/1\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        cm_all += cm\n",
    "\n",
    "    auc = roc_auc_score(y_true_all, probs_all)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_all, probs_all)\n",
    "    \n",
    "    plot_roc_curve(fpr, tpr, auc)\n",
    "    \n",
    "    print(\"len: {0} , {1}\".format(len(y_true_all), len(probs_all) ))\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(cm_all)\n",
    "    print(\"AUC: \")\n",
    "    print(auc)\n",
    "    print()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
