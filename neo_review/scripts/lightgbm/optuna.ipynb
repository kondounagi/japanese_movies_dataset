{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "matplotlib.rcParams['font.family']='IPAGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe\n",
    "\n",
    "base_path = \"../../data/dataframes/\"\n",
    "data = pd.read_pickle(base_path + 'data.pkl')\n",
    "nomination_onehot = pd.read_pickle(base_path + 'nomination_onehot.pkl')\n",
    "selected_performers_onehot = pd.read_pickle(base_path + 'selected_performers_onehot.pkl')\n",
    "selected_directors_onehot = pd.read_pickle(base_path + 'selected_directors_onehot.pkl')\n",
    "selected_studio_onehot = pd.read_pickle(base_path + 'selected_studio_onehot.pkl')\n",
    "selected_scriptwriter_onehot = pd.read_pickle(base_path + 'selected_scriptwriter_onehot.pkl')\n",
    "\n",
    "df = pd.concat(\n",
    "    [\n",
    "        nomination_onehot, \n",
    "        selected_performers_onehot,\n",
    "        selected_directors_onehot,\n",
    "        selected_studio_onehot,\n",
    "        selected_scriptwriter_onehot,\n",
    "        data[\"screen_time\"],\n",
    "        data[\"year\"]\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_x(x_train, x_test):\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    std_x_train = scaler.fit_transform(x_train)\n",
    "    std_x_test = scaler.transform(x_test)\n",
    "    return std_x_train, std_x_test\n",
    "\n",
    "\n",
    "def custom_train_test_split():\n",
    "    for year in range(1978, 2020):\n",
    "        train_x = df[df[\"year\"] != year].drop(\"year\", axis=1).values\n",
    "        test_x = df[df[\"year\"] == year].drop(\"year\", axis=1).values\n",
    "        train_y = data[data[\"year\"] != year][\"prize\"].values\n",
    "        test_y = data[data[\"year\"] == year][\"prize\"].values\n",
    "        std_train_x, std_test_x = standarize_x(train_x, test_x)\n",
    "        yield (std_train_x, std_test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #paramter_tuning using optuna\n",
    "    bagging_freq =  trial.suggest_int('bagging_freq',1,10),\n",
    "    min_data_in_leaf =  trial.suggest_int('min_data_in_leaf',2,100),\n",
    "    max_depth = trial.suggest_int('max_depth',1,20),\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate',0.001,0.1),\n",
    "    num_leaves = trial.suggest_int('num_leaves',2,70),\n",
    "    num_threads = trial.suggest_int('num_threads',1,10),\n",
    "    min_sum_hessian_in_leaf = trial.suggest_int('min_sum_hessian_in_leaf',1,10),\n",
    "        \n",
    "    lightgbm_tuna = lgb.LGBMRegressor(\n",
    "        random_state = 0,\n",
    "        verbosity = 1,\n",
    "        bagging_seed = 0,\n",
    "        boost_from_average = 'true',\n",
    "        boost = 'gbdt',\n",
    "        metric = 'auc',\n",
    "        bagging_freq = bagging_freq ,\n",
    "        min_data_in_leaf = min_data_in_leaf,\n",
    "        max_depth = max_depth,\n",
    "        learning_rate = learning_rate,\n",
    "        num_leaves = num_leaves,\n",
    "        num_threads = num_threads,\n",
    "        min_sum_hessian_in_leaf = min_sum_hessian_in_leaf\n",
    "    )\n",
    "    \n",
    "    total_auc = 0.0\n",
    "    auc_add_count = 0\n",
    "    \n",
    "    for (train_x, test_x, train_y, test_y) in custom_train_test_split(): \n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        lightgbm_tuna.fit(train_x, train_y)\n",
    "        pred_y = lightgbm_tuna.predict(test_x)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y, pos_label=1)\n",
    "        total_auc += auc(fpr, tpr)\n",
    "        auc_add_count += 1\n",
    "    \n",
    "    return total_auc / auc_add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-20 12:08:14,708] Finished trial#0 resulted in value: 0.4577380952380953. Current best value is 0.4577380952380953 with parameters: {'bagging_freq': 5, 'min_data_in_leaf': 75, 'max_depth': 6, 'learning_rate': 0.003390775101241283, 'num_leaves': 31, 'num_threads': 3, 'min_sum_hessian_in_leaf': 4}.\n",
      "[I 2019-08-20 12:08:20,413] Finished trial#1 resulted in value: 0.42083333333333334. Current best value is 0.4577380952380953 with parameters: {'bagging_freq': 5, 'min_data_in_leaf': 75, 'max_depth': 6, 'learning_rate': 0.003390775101241283, 'num_leaves': 31, 'num_threads': 3, 'min_sum_hessian_in_leaf': 4}.\n",
      "[I 2019-08-20 12:08:22,023] Finished trial#2 resulted in value: 0.7053571428571429. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:23,504] Finished trial#3 resulted in value: 0.44761904761904764. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:25,081] Finished trial#4 resulted in value: 0.5095238095238095. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:30,990] Finished trial#5 resulted in value: 0.4089285714285714. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:35,314] Finished trial#6 resulted in value: 0.49166666666666664. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:36,906] Finished trial#7 resulted in value: 0.39821428571428574. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n",
      "[I 2019-08-20 12:08:38,741] Finished trial#8 resulted in value: 0.4547619047619048. Current best value is 0.7053571428571429 with parameters: {'bagging_freq': 2, 'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.005305853988926544, 'num_leaves': 2, 'num_threads': 1, 'min_sum_hessian_in_leaf': 8}.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('  Value: {}'.format(trial.value))\n",
    "\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
