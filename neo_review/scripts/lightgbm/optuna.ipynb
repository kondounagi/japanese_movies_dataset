{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "matplotlib.rcParams['font.family']='IPAGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_generator():\n",
    "    base_path = \"../../data/std_data/\"\n",
    "    for year in range(1978, 2020):\n",
    "        train_x = pd.read_pickle(base_path + \"train/{}_x.pkl\".format(year)).values\n",
    "        test_x = pd.read_pickle(base_path + \"test/{}_x.pkl\".format(year)).values\n",
    "        train_y = pd.read_pickle(base_path + \"train/{}_y.pkl\".format(year)).values\n",
    "        test_y = pd.read_pickle(base_path + \"test/{}_y.pkl\".format(year)).values\n",
    "        yield (train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #paramter_tuning using optuna\n",
    "    param = {\n",
    "        #'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 2, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000, 10000),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        #'num_leaves': trial.suggest_int('num_leaves', 2, 1000),\n",
    "        #'num_threads': trial.suggest_int('num_threads',5, 10),\n",
    "        #'min_sum_hessian_in_leaf': trial.suggest_int('min_sum_hessian_in_leaf', 1, 10),\n",
    "        #'reg_alpha': trial.suggest_uniform('reg_alpha', 0., 1.0),\n",
    "        'reg_lambda': trial.suggest_uniform('reg_lambda', 0., 1.0),\n",
    "        #'class_weight': {str(class_name): 'balanced' for class_name in df.drop(\"year\", axis=1).columns}\n",
    "    }\n",
    "    \"\"\"\n",
    "    if param['boosting_type'] == 'dart':\n",
    "        param['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "        param['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "    if param['boosting_type'] == 'goss':\n",
    "        param['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "        param['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - param['top_rate'])\n",
    "\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Best trial:\n",
    "    Value: 0.7416173570019723\n",
    "    Params: \n",
    "    bagging_freq: 5\n",
    "    min_data_in_leaf: 17\n",
    "    max_depth: 8\n",
    "    learning_rate: 0.06221834301779217\n",
    "    num_leaves: 17\n",
    "    num_threads: 9\n",
    "    min_sum_hessian_in_leaf: 4\n",
    "    \"\"\"\n",
    "        \n",
    "    lightgbm_tuna = lgb.LGBMRegressor(\n",
    "        random_state=0,\n",
    "        verbosity=1,\n",
    "        bagging_seed=0,\n",
    "        boost_from_average='true',\n",
    "        metric='auc',\n",
    "        **param,\n",
    "    )\n",
    "        \n",
    "    pred_y_all = np.array([])\n",
    "    y_true_all = np.array([])\n",
    "    \n",
    "    data_gen = cv_generator()\n",
    "    \n",
    "    for (train_x, train_y, test_x, test_y) in data_gen: \n",
    "        dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "        lightgbm_tuna.fit(train_x, train_y)\n",
    "        pred_y = lightgbm_tuna.predict(test_x)\n",
    "        pred_y_all = np.hstack((pred_y_all, pred_y))\n",
    "        y_true_all = np.hstack((y_true_all, test_y))\n",
    "        \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true_all, pred_y_all, pos_label=1)\n",
    "    \n",
    "    return auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-08-22 11:17:57,621] Finished trial#0 resulted in value: 0.7364046210200056. Current best value is 0.7364046210200056 with parameters: {'bagging_freq': 9, 'max_depth': 10, 'learning_rate': 0.03919707013612227, 'n_estimators': 2304, 'subsample': 0.8154004316632215, 'reg_lambda': 0.9457727047152571}.\n",
      "[I 2019-08-22 11:18:57,832] Finished trial#1 resulted in value: 0.719921104536489. Current best value is 0.7364046210200056 with parameters: {'bagging_freq': 9, 'max_depth': 10, 'learning_rate': 0.03919707013612227, 'n_estimators': 2304, 'subsample': 0.8154004316632215, 'reg_lambda': 0.9457727047152571}.\n",
      "[I 2019-08-22 11:19:42,542] Finished trial#2 resulted in value: 0.7437306283460129. Current best value is 0.7437306283460129 with parameters: {'bagging_freq': 2, 'max_depth': 6, 'learning_rate': 0.013082241658870602, 'n_estimators': 3940, 'subsample': 0.7666542993450052, 'reg_lambda': 0.8916370347741254}.\n",
      "[I 2019-08-22 11:20:58,271] Finished trial#3 resulted in value: 0.7202028740490278. Current best value is 0.7437306283460129 with parameters: {'bagging_freq': 2, 'max_depth': 6, 'learning_rate': 0.013082241658870602, 'n_estimators': 3940, 'subsample': 0.7666542993450052, 'reg_lambda': 0.8916370347741254}.\n",
      "[I 2019-08-22 11:22:47,056] Finished trial#4 resulted in value: 0.7433079740772048. Current best value is 0.7437306283460129 with parameters: {'bagging_freq': 2, 'max_depth': 6, 'learning_rate': 0.013082241658870602, 'n_estimators': 3940, 'subsample': 0.7666542993450052, 'reg_lambda': 0.8916370347741254}.\n",
      "[I 2019-08-22 11:23:01,302] Finished trial#5 resulted in value: 0.6797689489997182. Current best value is 0.7437306283460129 with parameters: {'bagging_freq': 2, 'max_depth': 6, 'learning_rate': 0.013082241658870602, 'n_estimators': 3940, 'subsample': 0.7666542993450052, 'reg_lambda': 0.8916370347741254}.\n",
      "[I 2019-08-22 11:23:42,044] Finished trial#6 resulted in value: 0.7455621301775147. Current best value is 0.7455621301775147 with parameters: {'bagging_freq': 9, 'max_depth': 3, 'learning_rate': 0.03499667845127461, 'n_estimators': 4114, 'subsample': 0.6430735557314601, 'reg_lambda': 0.5721381352611769}.\n",
      "[I 2019-08-22 11:24:58,486] Finished trial#7 resulted in value: 0.7252747252747253. Current best value is 0.7455621301775147 with parameters: {'bagging_freq': 9, 'max_depth': 3, 'learning_rate': 0.03499667845127461, 'n_estimators': 4114, 'subsample': 0.6430735557314601, 'reg_lambda': 0.5721381352611769}.\n",
      "[I 2019-08-22 11:25:43,361] Finished trial#8 resulted in value: 0.7386587771203156. Current best value is 0.7455621301775147 with parameters: {'bagging_freq': 9, 'max_depth': 3, 'learning_rate': 0.03499667845127461, 'n_estimators': 4114, 'subsample': 0.6430735557314601, 'reg_lambda': 0.5721381352611769}.\n",
      "[I 2019-08-22 11:26:44,718] Finished trial#9 resulted in value: 0.7140039447731754. Current best value is 0.7455621301775147 with parameters: {'bagging_freq': 9, 'max_depth': 3, 'learning_rate': 0.03499667845127461, 'n_estimators': 4114, 'subsample': 0.6430735557314601, 'reg_lambda': 0.5721381352611769}.\n",
      "[I 2019-08-22 11:28:04,096] Finished trial#10 resulted in value: 0.7561284868977177. Current best value is 0.7561284868977177 with parameters: {'bagging_freq': 7, 'max_depth': 2, 'learning_rate': 0.07019440145024035, 'n_estimators': 9973, 'subsample': 0.6628548602119674, 'reg_lambda': 0.08228317005008123}.\n",
      "[I 2019-08-22 11:29:10,057] Finished trial#11 resulted in value: 0.6947027331642717. Current best value is 0.7561284868977177 with parameters: {'bagging_freq': 7, 'max_depth': 2, 'learning_rate': 0.07019440145024035, 'n_estimators': 9973, 'subsample': 0.6628548602119674, 'reg_lambda': 0.08228317005008123}.\n",
      "[I 2019-08-22 11:30:17,674] Finished trial#12 resulted in value: 0.6935756551141168. Current best value is 0.7561284868977177 with parameters: {'bagging_freq': 7, 'max_depth': 2, 'learning_rate': 0.07019440145024035, 'n_estimators': 9973, 'subsample': 0.6628548602119674, 'reg_lambda': 0.08228317005008123}.\n",
      "[I 2019-08-22 11:31:12,110] Finished trial#13 resulted in value: 0.6363764440687517. Current best value is 0.7561284868977177 with parameters: {'bagging_freq': 7, 'max_depth': 2, 'learning_rate': 0.07019440145024035, 'n_estimators': 9973, 'subsample': 0.6628548602119674, 'reg_lambda': 0.08228317005008123}.\n",
      "[I 2019-08-22 11:31:41,923] Finished trial#14 resulted in value: 0.7152719075795999. Current best value is 0.7561284868977177 with parameters: {'bagging_freq': 7, 'max_depth': 2, 'learning_rate': 0.07019440145024035, 'n_estimators': 9973, 'subsample': 0.6628548602119674, 'reg_lambda': 0.08228317005008123}.\n",
      "[I 2019-08-22 11:32:59,867] Finished trial#15 resulted in value: 0.7685263454494223. Current best value is 0.7685263454494223 with parameters: {'bagging_freq': 3, 'max_depth': 13, 'learning_rate': 0.060847727103930015, 'n_estimators': 5872, 'subsample': 0.6488504212164647, 'reg_lambda': 0.2008475122009793}.\n",
      "[I 2019-08-22 11:45:24,413] Finished trial#16 resulted in value: 0.724006762468301. Current best value is 0.7685263454494223 with parameters: {'bagging_freq': 3, 'max_depth': 13, 'learning_rate': 0.060847727103930015, 'n_estimators': 5872, 'subsample': 0.6488504212164647, 'reg_lambda': 0.2008475122009793}.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('  Value: {}'.format(trial.value))\n",
    "\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
