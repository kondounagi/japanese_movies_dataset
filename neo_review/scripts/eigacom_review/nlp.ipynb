{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/eigacom_review.json\", 'r') as f:\n",
    "    review_all = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MeCab.Tagger(\"-d /usr/lib64/mecab/dic/mecab-ipadic-neologd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wakachi(text):\n",
    "    LINE_SEPARATOR_PATTERN =  \"[\\n\\r\\u2028\\u2029\\u0085]\"\n",
    "    text = re.sub(LINE_SEPARATOR_PATTERN, ' ', text)\n",
    "    splitted = ' '.join([\n",
    "        x.split('\\t')[0] for x in m.parse(text.strip()).splitlines()[:-1] \n",
    "            if x.split('\\t')[1].split(',')[0] not in ['助詞', '助動詞', '接続詞', '動詞', '記号']\n",
    "    ])\n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_stopwords():\n",
    "    with open(\"../nlp/stopword_lda.txt\", \"r\") as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "        stopwords = [ss for ss in stopwords if not ss==u'']\n",
    "       \n",
    "    return stopwords\n",
    "\n",
    "stop_words  = set_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = []\n",
    "\n",
    "for key in review_all.keys():\n",
    "#     print(key)\n",
    "    reviews = review_all[key][\"reviews\"]\n",
    "    data = [] # １つのデータ映画の全てのレビューを繋げる\n",
    "    for r in reviews:\n",
    "        text = r[\"review\"].strip()\n",
    "        \n",
    "        tmp = []\n",
    "        for word in wakachi(text).split():\n",
    "             # ストップワード除去\n",
    "            if word not in stop_words and not word.isdigit():\n",
    "                data.append(word)\n",
    "\n",
    "    data_all.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# SEED = 6\n",
    "# np.random.seed(SEED)\n",
    "\n",
    "# 分類するトピック数\n",
    "topic_n = 20\n",
    "\n",
    "# 辞書を作成\n",
    "dictionary = Dictionary(data_all)\n",
    "\n",
    "# パラメータを設定\n",
    "# 1000単語以上には増やさない場合: keep_n=1000\n",
    "dictionary.filter_extremes(no_below=100,# 出現文書数が100回未満の単語を削除\n",
    "                           no_above=0.5,# 出現文書率が50％より大きい単語を削除\n",
    "                           ) \n",
    "# 各文書をBag-of-Wordsにより文書ベクトルに変換\n",
    "corpus_bow = [dictionary.doc2bow(text) for text in data_all]\n",
    "\n",
    "# LDAの学習\n",
    "lda = LdaModel(corpus=corpus_bow, num_topics=topic_n, id2word=dictionary)\n",
    "\n",
    "# LDAの学習には時間がかかるので、学習したモデルは保存\n",
    "# model_pref = 'model/lda'\n",
    "# lda.save(model_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トピック 0 :  0.347*\"原作\" + 0.104*\"役者\" + 0.100*\"台詞\" + 0.092*\"俳優\" + 0.089*\"展開\" + 0.081*\"無い\" + 0.075*\"残念\" + 0.074*\"一番\" + 0.039*\"雰囲気\"\n",
      "トピック 1 :  0.331*\"一番\" + 0.141*\"展開\" + 0.119*\"無い\" + 0.113*\"残念\" + 0.109*\"台詞\" + 0.079*\"雰囲気\" + 0.049*\"原作\" + 0.043*\"役者\" + 0.015*\"俳優\"\n",
      "トピック 2 :  0.444*\"原作\" + 0.087*\"展開\" + 0.086*\"役者\" + 0.085*\"残念\" + 0.083*\"俳優\" + 0.063*\"雰囲気\" + 0.061*\"一番\" + 0.055*\"無い\" + 0.037*\"台詞\"\n",
      "トピック 3 :  0.413*\"残念\" + 0.108*\"無い\" + 0.087*\"一番\" + 0.086*\"台詞\" + 0.084*\"展開\" + 0.083*\"役者\" + 0.072*\"俳優\" + 0.052*\"雰囲気\" + 0.015*\"原作\"\n",
      "トピック 4 :  0.345*\"原作\" + 0.216*\"俳優\" + 0.154*\"無い\" + 0.102*\"残念\" + 0.080*\"展開\" + 0.075*\"雰囲気\" + 0.014*\"役者\" + 0.009*\"一番\" + 0.006*\"台詞\"\n",
      "トピック 5 :  0.232*\"俳優\" + 0.217*\"原作\" + 0.165*\"役者\" + 0.109*\"無い\" + 0.083*\"一番\" + 0.078*\"台詞\" + 0.065*\"展開\" + 0.030*\"残念\" + 0.022*\"雰囲気\"\n",
      "トピック 6 :  0.111*\"俳優\" + 0.111*\"原作\" + 0.111*\"台詞\" + 0.111*\"展開\" + 0.111*\"役者\" + 0.111*\"残念\" + 0.111*\"雰囲気\" + 0.111*\"一番\" + 0.111*\"無い\"\n",
      "トピック 7 :  0.194*\"無い\" + 0.170*\"展開\" + 0.143*\"一番\" + 0.126*\"残念\" + 0.116*\"俳優\" + 0.089*\"役者\" + 0.086*\"台詞\" + 0.060*\"雰囲気\" + 0.017*\"原作\"\n",
      "トピック 8 :  0.341*\"俳優\" + 0.136*\"原作\" + 0.126*\"一番\" + 0.123*\"台詞\" + 0.115*\"役者\" + 0.061*\"雰囲気\" + 0.039*\"展開\" + 0.031*\"残念\" + 0.029*\"無い\"\n",
      "トピック 9 :  0.232*\"無い\" + 0.232*\"雰囲気\" + 0.175*\"一番\" + 0.175*\"原作\" + 0.060*\"俳優\" + 0.060*\"台詞\" + 0.060*\"展開\" + 0.003*\"役者\" + 0.003*\"残念\"\n",
      "トピック 10 :  0.363*\"俳優\" + 0.156*\"展開\" + 0.145*\"原作\" + 0.108*\"役者\" + 0.066*\"残念\" + 0.059*\"雰囲気\" + 0.049*\"一番\" + 0.029*\"無い\" + 0.024*\"台詞\"\n",
      "トピック 11 :  0.219*\"俳優\" + 0.153*\"役者\" + 0.136*\"残念\" + 0.121*\"一番\" + 0.105*\"展開\" + 0.101*\"雰囲気\" + 0.085*\"台詞\" + 0.061*\"無い\" + 0.019*\"原作\"\n",
      "トピック 12 :  0.359*\"雰囲気\" + 0.180*\"役者\" + 0.136*\"台詞\" + 0.091*\"一番\" + 0.091*\"展開\" + 0.047*\"原作\" + 0.047*\"残念\" + 0.047*\"俳優\" + 0.002*\"無い\"\n",
      "トピック 13 :  0.245*\"役者\" + 0.231*\"俳優\" + 0.212*\"原作\" + 0.108*\"展開\" + 0.074*\"一番\" + 0.051*\"無い\" + 0.029*\"残念\" + 0.028*\"台詞\" + 0.022*\"雰囲気\"\n",
      "トピック 14 :  0.178*\"台詞\" + 0.145*\"展開\" + 0.144*\"無い\" + 0.127*\"俳優\" + 0.119*\"残念\" + 0.105*\"一番\" + 0.083*\"役者\" + 0.053*\"雰囲気\" + 0.046*\"原作\"\n",
      "トピック 15 :  0.237*\"展開\" + 0.212*\"役者\" + 0.177*\"俳優\" + 0.117*\"一番\" + 0.068*\"無い\" + 0.064*\"残念\" + 0.054*\"原作\" + 0.036*\"台詞\" + 0.034*\"雰囲気\"\n",
      "トピック 16 :  0.281*\"展開\" + 0.175*\"台詞\" + 0.165*\"俳優\" + 0.111*\"役者\" + 0.077*\"一番\" + 0.069*\"残念\" + 0.061*\"無い\" + 0.053*\"雰囲気\" + 0.009*\"原作\"\n",
      "トピック 17 :  0.407*\"残念\" + 0.122*\"無い\" + 0.105*\"展開\" + 0.101*\"台詞\" + 0.072*\"役者\" + 0.070*\"一番\" + 0.064*\"俳優\" + 0.052*\"雰囲気\" + 0.006*\"原作\"\n",
      "トピック 18 :  0.240*\"役者\" + 0.160*\"無い\" + 0.140*\"俳優\" + 0.125*\"展開\" + 0.100*\"残念\" + 0.085*\"一番\" + 0.072*\"台詞\" + 0.058*\"雰囲気\" + 0.019*\"原作\"\n",
      "トピック 19 :  0.252*\"残念\" + 0.188*\"無い\" + 0.103*\"雰囲気\" + 0.100*\"一番\" + 0.098*\"台詞\" + 0.086*\"展開\" + 0.085*\"役者\" + 0.080*\"俳優\" + 0.009*\"原作\"\n"
     ]
    }
   ],
   "source": [
    "for tpn in range(topic_n):\n",
    "    print('トピック', tpn, ': ', lda.print_topic(tpn, topn = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = []\n",
    "\n",
    "for id in range(1, 211):\n",
    "    frame.append([id] + [0 for i in range(topic_n)])\n",
    "    \n",
    "for id in range(1, 211):\n",
    "    for topic_num , prob  in lda[corpus_bow[id]]:\n",
    "        frame[id-1][topic_n + 1] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'apend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6e659cef343b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"topic_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'apend'"
     ]
    }
   ],
   "source": [
    "for i in range(topic_n):\n",
    "    df_columns = df_columns.append(\"topic_{}\".format(str(i)))\n",
    "\n",
    "df = pd.DataFrame(frame, columns=df_columns)\n",
    "df = df.set_index('id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./topics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_all = []\n",
    "\n",
    "for id in range(1, 211):\n",
    "#     print(id)\n",
    "    cate, weight = sorted(lda[corpus_bow[id]], key=lambda x: x[1], reverse=True)[0]\n",
    "    category_all.append(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/nominate_movie_meta_data.json\", 'r') as fs:\n",
    "    j = json.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prize = []\n",
    "prize_id = []\n",
    "for i in j:\n",
    "    for item in j[i]:\n",
    "        prize.append(item[\"prize\"])\n",
    "        if item[\"prize\"]:\n",
    "            prize_id.append(item[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6\n",
      "11\n",
      "16\n",
      "21\n",
      "26\n",
      "31\n",
      "36\n",
      "41\n",
      "46\n",
      "51\n",
      "56\n",
      "61\n",
      "66\n",
      "71\n",
      "76\n",
      "81\n",
      "86\n",
      "91\n",
      "96\n",
      "101\n",
      "106\n",
      "111\n",
      "116\n",
      "121\n",
      "126\n",
      "131\n",
      "136\n",
      "141\n",
      "146\n",
      "151\n",
      "156\n",
      "161\n",
      "166\n",
      "171\n",
      "176\n",
      "181\n",
      "187\n",
      "192\n",
      "197\n",
      "202\n",
      "207\n"
     ]
    }
   ],
   "source": [
    "category = []\n",
    "for id in prize_id:\n",
    "    print(id)\n",
    "    cate, wight = sorted(lda[corpus_bow[id]], key=lambda x: x[1], reverse=True)[0]\n",
    "    category.append(cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9\n",
      "1 0\n",
      "2 4\n",
      "3 1\n",
      "4 0\n",
      "5 0\n",
      "6 4\n",
      "7 1\n",
      "8 3\n",
      "9 4\n",
      "10 2\n",
      "11 1\n",
      "12 2\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 4\n",
      "17 1\n",
      "18 2\n",
      "19 4\n"
     ]
    }
   ],
   "source": [
    "category_count = []\n",
    "for i in range(topic_n):\n",
    "    c = category.count(i)\n",
    "    category_count.append(c)\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 45\n",
      "1 4\n",
      "2 16\n",
      "3 10\n",
      "4 7\n",
      "5 1\n",
      "6 15\n",
      "7 2\n",
      "8 12\n",
      "9 20\n",
      "10 6\n",
      "11 3\n",
      "12 6\n",
      "13 0\n",
      "14 1\n",
      "15 0\n",
      "16 16\n",
      "17 6\n",
      "18 6\n",
      "19 34\n"
     ]
    }
   ],
   "source": [
    "category_all_count = []\n",
    "for i in range(topic_n):\n",
    "    c = category_all.count(i)\n",
    "    category_all_count.append(c)\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2\n",
      "1 0.0\n",
      "2 0.25\n",
      "3 0.1\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.26666666666666666\n",
      "7 0.5\n",
      "8 0.25\n",
      "9 0.2\n",
      "10 0.3333333333333333\n",
      "11 0.3333333333333333\n",
      "12 0.3333333333333333\n",
      "13 nan\n",
      "14 0.0\n",
      "15 nan\n",
      "16 0.25\n",
      "17 0.16666666666666666\n",
      "18 0.3333333333333333\n",
      "19 0.11764705882352941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamoto/venv/lib64/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(np.array(category_count)/np.array(category_all_count)):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.21428571428571427\n",
      "1 0.0\n",
      "2 0.09523809523809523\n",
      "3 0.023809523809523808\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.09523809523809523\n",
      "7 0.023809523809523808\n",
      "8 0.07142857142857142\n",
      "9 0.09523809523809523\n",
      "10 0.047619047619047616\n",
      "11 0.023809523809523808\n",
      "12 0.047619047619047616\n",
      "13 0.0\n",
      "14 0.0\n",
      "15 0.0\n",
      "16 0.09523809523809523\n",
      "17 0.023809523809523808\n",
      "18 0.047619047619047616\n",
      "19 0.09523809523809523\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(np.array(category_count)/np.sum(category_count)):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.21428571428571427\n",
      "1 0.01904761904761905\n",
      "2 0.0761904761904762\n",
      "3 0.047619047619047616\n",
      "4 0.03333333333333333\n",
      "5 0.004761904761904762\n",
      "6 0.07142857142857142\n",
      "7 0.009523809523809525\n",
      "8 0.05714285714285714\n",
      "9 0.09523809523809523\n",
      "10 0.02857142857142857\n",
      "11 0.014285714285714285\n",
      "12 0.02857142857142857\n",
      "13 0.0\n",
      "14 0.004761904761904762\n",
      "15 0.0\n",
      "16 0.0761904761904762\n",
      "17 0.02857142857142857\n",
      "18 0.02857142857142857\n",
      "19 0.1619047619047619\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(np.array(category_all_count)/np.sum(category_all_count)):\n",
    "    print(i, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
